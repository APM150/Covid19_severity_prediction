{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading county-level data...\n",
      "loaded and merged COVID-19 cases/deaths data successfully\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import load_data\n",
    "from Project_Models import RNN_Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def normalize(x):\n",
    "    maxtensor = x.max(0, keepdim=True)[0]\n",
    "    maxtensor[maxtensor==0] = 1e-4\n",
    "    x_normed = x / maxtensor\n",
    "    return x_normed, maxtensor\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "df = load_data.load_county_level()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "#x nan: 0\nx: tensor([[[0.1579, 0.1496, 0.2425, 0.7638, 0.0000, 0.0000],\n         [0.1579, 0.1496, 0.2425, 0.7638, 0.0000, 0.0000],\n         [0.1579, 0.1496, 0.2425, 0.7638, 0.0000, 0.0000],\n         ...,\n         [0.1579, 0.1496, 0.2425, 0.7638, 0.2434, 1.0000],\n         [0.1579, 0.1496, 0.2425, 0.7638, 0.2433, 1.0000],\n         [0.1579, 0.1496, 0.2425, 0.7638, 0.2426, 1.0000]],\n\n        [[0.0789, 0.0607, 0.2413, 0.8031, 0.0000, 0.0000],\n         [0.0789, 0.0607, 0.2413, 0.8031, 0.0000, 0.0000],\n         [0.0789, 0.0607, 0.2413, 0.8031, 0.0000, 0.0000],\n         ...,\n         [0.0789, 0.0607, 0.2413, 0.8031, 0.2464, 0.9824],\n         [0.0789, 0.0607, 0.2413, 0.8031, 0.2463, 0.9827],\n         [0.0789, 0.0607, 0.2413, 0.8031, 0.2456, 0.9825]],\n\n        [[1.0000, 1.0000, 1.0000, 0.6378, 0.0000, 0.0000],\n         [1.0000, 1.0000, 1.0000, 0.6378, 0.0000, 0.0000],\n         [1.0000, 1.0000, 1.0000, 0.6378, 0.0000, 0.0000],\n         ...,\n         [1.0000, 1.0000, 1.0000, 0.6378, 1.0000, 0.9648],\n         [1.0000, 1.0000, 1.0000, 0.6378, 1.0000, 0.9652],\n         [1.0000, 1.0000, 1.0000, 0.6378, 1.0000, 0.9677]],\n\n        ...,\n\n        [[0.1053, 0.2215, 0.0788, 0.9213, 0.0000, 0.0000],\n         [0.1053, 0.2215, 0.0788, 0.9213, 0.0000, 0.0000],\n         [0.1053, 0.2215, 0.0788, 0.9213, 0.0000, 0.0000],\n         ...,\n         [0.1053, 0.2215, 0.0788, 0.9213, 0.0802, 0.0542],\n         [0.1053, 0.2215, 0.0788, 0.9213, 0.0803, 0.0542],\n         [0.1053, 0.2215, 0.0788, 0.9213, 0.0805, 0.0550]],\n\n        [[0.1184, 0.1472, 0.1860, 0.5748, 0.0000, 0.0000],\n         [0.1184, 0.1472, 0.1860, 0.5748, 0.0000, 0.0000],\n         [0.1184, 0.1472, 0.1860, 0.5748, 0.0000, 0.0000],\n         ...,\n         [0.1184, 0.1472, 0.1860, 0.5748, 0.0822, 0.0578],\n         [0.1184, 0.1472, 0.1860, 0.5748, 0.0826, 0.0582],\n         [0.1184, 0.1472, 0.1860, 0.5748, 0.0828, 0.0586]],\n\n        [[0.0395, 0.0334, 0.0543, 0.8819, 0.0000, 0.0000],\n         [0.0395, 0.0334, 0.0543, 0.8819, 0.0000, 0.0000],\n         [0.0395, 0.0334, 0.0543, 0.8819, 0.0000, 0.0000],\n         ...,\n         [0.0395, 0.0334, 0.0543, 0.8819, 0.0321, 0.0588],\n         [0.0395, 0.0334, 0.0543, 0.8819, 0.0323, 0.0588],\n         [0.0395, 0.0334, 0.0543, 0.8819, 0.0325, 0.0587]]], device='cuda:0')\n#y nan: 0\ny: tensor([[ 79558.0000,   7441.0000],\n        [ 80555.0000,   7317.0000],\n        [327964.0000,   7216.0000],\n        [231462.0000,   5717.0000],\n        [ 57657.0000,   5014.0000],\n        [170207.0000,   3747.0002],\n        [195991.0000,   3693.0000],\n        [ 38668.0000,   3200.0000],\n        [ 48200.0000,   3104.0000],\n        [168746.0156,   2877.0000],\n        [ 38280.0000,   2333.0000],\n        [ 52575.0000,   2226.0000],\n        [ 28451.0000,   2161.0000],\n        [ 27678.0000,   2075.0000],\n        [ 51744.0039,   2023.0001],\n        [ 45578.0000,   1914.0000],\n        [ 37031.0000,   1750.0000],\n        [ 56509.0039,   1614.0000],\n        [ 90885.0000,   1590.0000],\n        [ 92148.0000,   1564.0000],\n        [ 25671.0000,   1540.0000],\n        [ 21211.9980,   1525.0000],\n        [ 63165.0000,   1514.0000],\n        [ 42940.0000,   1482.0000],\n        [ 24606.0000,   1460.0000],\n        [ 28731.0000,   1451.0000],\n        [ 68376.0000,   1438.0000],\n        [ 22824.0000,   1383.0000],\n        [ 27938.0000,   1382.0000],\n        [ 72341.0000,   1352.0000],\n        [104450.9922,   1341.0000],\n        [ 23388.0000,   1273.0000],\n        [ 32405.9980,   1260.0000],\n        [ 21656.0000,   1204.0000],\n        [ 32542.0000,   1201.0000],\n        [ 20892.0000,   1151.0000],\n        [ 14642.0010,   1136.0000],\n        [ 24953.0000,   1130.0000],\n        [ 18876.0000,   1104.0000],\n        [ 71072.0000,   1096.0000],\n        [ 17933.0000,   1080.0000],\n        [ 46555.0000,   1033.0000],\n        [ 24825.0000,    993.0000],\n        [ 27808.0020,    986.0000],\n        [ 61053.0000,    915.0000],\n        [ 16115.0000,    900.0000],\n        [ 35074.0000,    899.0000],\n        [ 27969.0000,    899.0000],\n        [ 68042.0000,    892.0000],\n        [ 35146.0000,    876.0000],\n        [ 15729.0000,    876.0000],\n        [ 32204.0000,    863.0000],\n        [ 12993.0010,    862.0000],\n        [ 51635.0000,    851.0000],\n        [ 10550.0000,    844.0000],\n        [ 12251.0010,    842.0000],\n        [ 28242.0000,    838.0000],\n        [ 31496.9980,    829.0000],\n        [ 15420.0000,    784.0000],\n        [ 15592.0000,    779.0000],\n        [ 67484.0000,    729.0000],\n        [ 26048.0000,    715.0000],\n        [ 23104.0020,    688.0000],\n        [ 16028.0010,    676.0000],\n        [ 31204.0020,    669.0000],\n        [ 18379.0000,    657.0000],\n        [ 32487.0000,    648.0000],\n        [ 39917.0000,    645.0000],\n        [ 33099.0000,    644.0000],\n        [ 13638.0000,    644.0000],\n        [ 10368.0000,    643.0000],\n        [ 24661.0020,    643.0000],\n        [ 11921.0000,    635.0000],\n        [ 55471.0000,    632.0000],\n        [ 25791.0000,    609.0000],\n        [ 41003.0000,    603.0000],\n        [ 14034.0000,    602.0000],\n        [ 49752.0000,    601.0000],\n        [  7212.0000,    600.0000],\n        [ 19302.0000,    592.0000],\n        [ 37494.0000,    544.0000],\n        [ 25316.0000,    538.0000],\n        [ 27920.0000,    538.0000],\n        [  9728.0000,    522.0000],\n        [ 19768.0000,    519.0000],\n        [ 19277.0000,    516.0000],\n        [ 29014.0000,    514.0000],\n        [ 22993.0000,    500.0000],\n        [ 11271.0000,    492.0000],\n        [ 25249.0000,    483.0000],\n        [ 23400.9980,    479.0000],\n        [ 26627.0000,    470.0000],\n        [ 32648.0000,    465.0000],\n        [ 16793.0000,    462.0000],\n        [ 24769.0000,    461.0000],\n        [ 32755.0000,    456.0000],\n        [ 33559.0000,    456.0000],\n        [ 26514.0000,    442.0000],\n        [ 27124.0000,    440.0000],\n        [ 10766.9990,    438.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "maxload = 100\n",
    "\n",
    "x = form_input_tensor(df, ['#Hospitals', '#ICU_beds', 'MedicareEnrollment,AgedTot2017', 'DiabetesPercentage'], maxload=maxload).to(device)\n",
    "x, xmaxtensor = normalize(x)\n",
    "print(f\"#x nan: {(torch.sum(torch.isnan(x)))}\")\n",
    "print(\"x:\", x)\n",
    "\n",
    "y = form_labels_tensor(df, maxload=maxload).to(device)\n",
    "y, ymaxtensor = normalize(y)\n",
    "print(f\"#y nan: {torch.sum(torch.isnan(y))}\")\n",
    "print(\"y:\", y * ymaxtensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0276\n",
      "Epoch [159/800], Loss: 0.0276\n",
      "Epoch [160/800], Loss: 0.0276\n",
      "Epoch [161/800], Loss: 0.0276\n",
      "Epoch [162/800], Loss: 0.0276\n",
      "Epoch [163/800], Loss: 0.0276\n",
      "Epoch [164/800], Loss: 0.0276\n",
      "Epoch [165/800], Loss: 0.0276\n",
      "Epoch [166/800], Loss: 0.0276\n",
      "Epoch [167/800], Loss: 0.0276\n",
      "Epoch [168/800], Loss: 0.0276\n",
      "Epoch [169/800], Loss: 0.0276\n",
      "Epoch [170/800], Loss: 0.0276\n",
      "Epoch [171/800], Loss: 0.0276\n",
      "Epoch [172/800], Loss: 0.0276\n",
      "Epoch [173/800], Loss: 0.0276\n",
      "Epoch [174/800], Loss: 0.0276\n",
      "Epoch [175/800], Loss: 0.0276\n",
      "Epoch [176/800], Loss: 0.0276\n",
      "Epoch [177/800], Loss: 0.0276\n",
      "Epoch [178/800], Loss: 0.0276\n",
      "Epoch [179/800], Loss: 0.0276\n",
      "Epoch [180/800], Loss: 0.0276\n",
      "Epoch [181/800], Loss: 0.0276\n",
      "Epoch [182/800], Loss: 0.0276\n",
      "Epoch [183/800], Loss: 0.0276\n",
      "Epoch [184/800], Loss: 0.0276\n",
      "Epoch [185/800], Loss: 0.0276\n",
      "Epoch [186/800], Loss: 0.0276\n",
      "Epoch [187/800], Loss: 0.0276\n",
      "Epoch [188/800], Loss: 0.0276\n",
      "Epoch [189/800], Loss: 0.0276\n",
      "Epoch [190/800], Loss: 0.0276\n",
      "Epoch [191/800], Loss: 0.0276\n",
      "Epoch [192/800], Loss: 0.0276\n",
      "Epoch [193/800], Loss: 0.0276\n",
      "Epoch [194/800], Loss: 0.0276\n",
      "Epoch [195/800], Loss: 0.0276\n",
      "Epoch [196/800], Loss: 0.0276\n",
      "Epoch [197/800], Loss: 0.0276\n",
      "Epoch [198/800], Loss: 0.0276\n",
      "Epoch [199/800], Loss: 0.0276\n",
      "Epoch [200/800], Loss: 0.0276\n",
      "Epoch [201/800], Loss: 0.0276\n",
      "Epoch [202/800], Loss: 0.0276\n",
      "Epoch [203/800], Loss: 0.0276\n",
      "Epoch [204/800], Loss: 0.0276\n",
      "Epoch [205/800], Loss: 0.0276\n",
      "Epoch [206/800], Loss: 0.0276\n",
      "Epoch [207/800], Loss: 0.0276\n",
      "Epoch [208/800], Loss: 0.0276\n",
      "Epoch [209/800], Loss: 0.0276\n",
      "Epoch [210/800], Loss: 0.0276\n",
      "Epoch [211/800], Loss: 0.0276\n",
      "Epoch [212/800], Loss: 0.0276\n",
      "Epoch [213/800], Loss: 0.0276\n",
      "Epoch [214/800], Loss: 0.0276\n",
      "Epoch [215/800], Loss: 0.0276\n",
      "Epoch [216/800], Loss: 0.0276\n",
      "Epoch [217/800], Loss: 0.0276\n",
      "Epoch [218/800], Loss: 0.0276\n",
      "Epoch [219/800], Loss: 0.0276\n",
      "Epoch [220/800], Loss: 0.0276\n",
      "Epoch [221/800], Loss: 0.0276\n",
      "Epoch [222/800], Loss: 0.0276\n",
      "Epoch [223/800], Loss: 0.0276\n",
      "Epoch [224/800], Loss: 0.0276\n",
      "Epoch [225/800], Loss: 0.0276\n",
      "Epoch [226/800], Loss: 0.0276\n",
      "Epoch [227/800], Loss: 0.0276\n",
      "Epoch [228/800], Loss: 0.0276\n",
      "Epoch [229/800], Loss: 0.0276\n",
      "Epoch [230/800], Loss: 0.0276\n",
      "Epoch [231/800], Loss: 0.0276\n",
      "Epoch [232/800], Loss: 0.0276\n",
      "Epoch [233/800], Loss: 0.0276\n",
      "Epoch [234/800], Loss: 0.0276\n",
      "Epoch [235/800], Loss: 0.0276\n",
      "Epoch [236/800], Loss: 0.0276\n",
      "Epoch [237/800], Loss: 0.0276\n",
      "Epoch [238/800], Loss: 0.0276\n",
      "Epoch [239/800], Loss: 0.0276\n",
      "Epoch [240/800], Loss: 0.0276\n",
      "Epoch [241/800], Loss: 0.0276\n",
      "Epoch [242/800], Loss: 0.0276\n",
      "Epoch [243/800], Loss: 0.0276\n",
      "Epoch [244/800], Loss: 0.0276\n",
      "Epoch [245/800], Loss: 0.0276\n",
      "Epoch [246/800], Loss: 0.0276\n",
      "Epoch [247/800], Loss: 0.0276\n",
      "Epoch [248/800], Loss: 0.0276\n",
      "Epoch [249/800], Loss: 0.0276\n",
      "Epoch [250/800], Loss: 0.0276\n",
      "Epoch [251/800], Loss: 0.0276\n",
      "Epoch [252/800], Loss: 0.0276\n",
      "Epoch [253/800], Loss: 0.0276\n",
      "Epoch [254/800], Loss: 0.0276\n",
      "Epoch [255/800], Loss: 0.0276\n",
      "Epoch [256/800], Loss: 0.0276\n",
      "Epoch [257/800], Loss: 0.0276\n",
      "Epoch [258/800], Loss: 0.0276\n",
      "Epoch [259/800], Loss: 0.0276\n",
      "Epoch [260/800], Loss: 0.0276\n",
      "Epoch [261/800], Loss: 0.0276\n",
      "Epoch [262/800], Loss: 0.0276\n",
      "Epoch [263/800], Loss: 0.0276\n",
      "Epoch [264/800], Loss: 0.0276\n",
      "Epoch [265/800], Loss: 0.0276\n",
      "Epoch [266/800], Loss: 0.0276\n",
      "Epoch [267/800], Loss: 0.0276\n",
      "Epoch [268/800], Loss: 0.0276\n",
      "Epoch [269/800], Loss: 0.0276\n",
      "Epoch [270/800], Loss: 0.0276\n",
      "Epoch [271/800], Loss: 0.0276\n",
      "Epoch [272/800], Loss: 0.0276\n",
      "Epoch [273/800], Loss: 0.0276\n",
      "Epoch [274/800], Loss: 0.0276\n",
      "Epoch [275/800], Loss: 0.0276\n",
      "Epoch [276/800], Loss: 0.0276\n",
      "Epoch [277/800], Loss: 0.0276\n",
      "Epoch [278/800], Loss: 0.0276\n",
      "Epoch [279/800], Loss: 0.0276\n",
      "Epoch [280/800], Loss: 0.0276\n",
      "Epoch [281/800], Loss: 0.0276\n",
      "Epoch [282/800], Loss: 0.0276\n",
      "Epoch [283/800], Loss: 0.0276\n",
      "Epoch [284/800], Loss: 0.0276\n",
      "Epoch [285/800], Loss: 0.0276\n",
      "Epoch [286/800], Loss: 0.0276\n",
      "Epoch [287/800], Loss: 0.0276\n",
      "Epoch [288/800], Loss: 0.0276\n",
      "Epoch [289/800], Loss: 0.0276\n",
      "Epoch [290/800], Loss: 0.0276\n",
      "Epoch [291/800], Loss: 0.0276\n",
      "Epoch [292/800], Loss: 0.0276\n",
      "Epoch [293/800], Loss: 0.0276\n",
      "Epoch [294/800], Loss: 0.0276\n",
      "Epoch [295/800], Loss: 0.0276\n",
      "Epoch [296/800], Loss: 0.0276\n",
      "Epoch [297/800], Loss: 0.0276\n",
      "Epoch [298/800], Loss: 0.0276\n",
      "Epoch [299/800], Loss: 0.0276\n",
      "Epoch [300/800], Loss: 0.0276\n",
      "Epoch [301/800], Loss: 0.0276\n",
      "Epoch [302/800], Loss: 0.0276\n",
      "Epoch [303/800], Loss: 0.0276\n",
      "Epoch [304/800], Loss: 0.0276\n",
      "Epoch [305/800], Loss: 0.0276\n",
      "Epoch [306/800], Loss: 0.0276\n",
      "Epoch [307/800], Loss: 0.0276\n",
      "Epoch [308/800], Loss: 0.0276\n",
      "Epoch [309/800], Loss: 0.0276\n",
      "Epoch [310/800], Loss: 0.0276\n",
      "Epoch [311/800], Loss: 0.0276\n",
      "Epoch [312/800], Loss: 0.0276\n",
      "Epoch [313/800], Loss: 0.0276\n",
      "Epoch [314/800], Loss: 0.0276\n",
      "Epoch [315/800], Loss: 0.0276\n",
      "Epoch [316/800], Loss: 0.0276\n",
      "Epoch [317/800], Loss: 0.0276\n",
      "Epoch [318/800], Loss: 0.0276\n",
      "Epoch [319/800], Loss: 0.0276\n",
      "Epoch [320/800], Loss: 0.0276\n",
      "Epoch [321/800], Loss: 0.0276\n",
      "Epoch [322/800], Loss: 0.0276\n",
      "Epoch [323/800], Loss: 0.0276\n",
      "Epoch [324/800], Loss: 0.0276\n",
      "Epoch [325/800], Loss: 0.0276\n",
      "Epoch [326/800], Loss: 0.0276\n",
      "Epoch [327/800], Loss: 0.0276\n",
      "Epoch [328/800], Loss: 0.0276\n",
      "Epoch [329/800], Loss: 0.0276\n",
      "Epoch [330/800], Loss: 0.0276\n",
      "Epoch [331/800], Loss: 0.0276\n",
      "Epoch [332/800], Loss: 0.0276\n",
      "Epoch [333/800], Loss: 0.0275\n",
      "Epoch [334/800], Loss: 0.0275\n",
      "Epoch [335/800], Loss: 0.0275\n",
      "Epoch [336/800], Loss: 0.0275\n",
      "Epoch [337/800], Loss: 0.0275\n",
      "Epoch [338/800], Loss: 0.0275\n",
      "Epoch [339/800], Loss: 0.0275\n",
      "Epoch [340/800], Loss: 0.0275\n",
      "Epoch [341/800], Loss: 0.0275\n",
      "Epoch [342/800], Loss: 0.0275\n",
      "Epoch [343/800], Loss: 0.0275\n",
      "Epoch [344/800], Loss: 0.0275\n",
      "Epoch [345/800], Loss: 0.0275\n",
      "Epoch [346/800], Loss: 0.0275\n",
      "Epoch [347/800], Loss: 0.0275\n",
      "Epoch [348/800], Loss: 0.0275\n",
      "Epoch [349/800], Loss: 0.0275\n",
      "Epoch [350/800], Loss: 0.0275\n",
      "Epoch [351/800], Loss: 0.0275\n",
      "Epoch [352/800], Loss: 0.0275\n",
      "Epoch [353/800], Loss: 0.0275\n",
      "Epoch [354/800], Loss: 0.0275\n",
      "Epoch [355/800], Loss: 0.0275\n",
      "Epoch [356/800], Loss: 0.0275\n",
      "Epoch [357/800], Loss: 0.0275\n",
      "Epoch [358/800], Loss: 0.0275\n",
      "Epoch [359/800], Loss: 0.0275\n",
      "Epoch [360/800], Loss: 0.0275\n",
      "Epoch [361/800], Loss: 0.0275\n",
      "Epoch [362/800], Loss: 0.0275\n",
      "Epoch [363/800], Loss: 0.0275\n",
      "Epoch [364/800], Loss: 0.0275\n",
      "Epoch [365/800], Loss: 0.0274\n",
      "Epoch [366/800], Loss: 0.0274\n",
      "Epoch [367/800], Loss: 0.0274\n",
      "Epoch [368/800], Loss: 0.0274\n",
      "Epoch [369/800], Loss: 0.0274\n",
      "Epoch [370/800], Loss: 0.0274\n",
      "Epoch [371/800], Loss: 0.0274\n",
      "Epoch [372/800], Loss: 0.0274\n",
      "Epoch [373/800], Loss: 0.0274\n",
      "Epoch [374/800], Loss: 0.0274\n",
      "Epoch [375/800], Loss: 0.0274\n",
      "Epoch [376/800], Loss: 0.0274\n",
      "Epoch [377/800], Loss: 0.0274\n",
      "Epoch [378/800], Loss: 0.0274\n",
      "Epoch [379/800], Loss: 0.0274\n",
      "Epoch [380/800], Loss: 0.0274\n",
      "Epoch [381/800], Loss: 0.0274\n",
      "Epoch [382/800], Loss: 0.0273\n",
      "Epoch [383/800], Loss: 0.0273\n",
      "Epoch [384/800], Loss: 0.0273\n",
      "Epoch [385/800], Loss: 0.0273\n",
      "Epoch [386/800], Loss: 0.0273\n",
      "Epoch [387/800], Loss: 0.0273\n",
      "Epoch [388/800], Loss: 0.0273\n",
      "Epoch [389/800], Loss: 0.0273\n",
      "Epoch [390/800], Loss: 0.0273\n",
      "Epoch [391/800], Loss: 0.0273\n",
      "Epoch [392/800], Loss: 0.0272\n",
      "Epoch [393/800], Loss: 0.0272\n",
      "Epoch [394/800], Loss: 0.0272\n",
      "Epoch [395/800], Loss: 0.0272\n",
      "Epoch [396/800], Loss: 0.0272\n",
      "Epoch [397/800], Loss: 0.0272\n",
      "Epoch [398/800], Loss: 0.0272\n",
      "Epoch [399/800], Loss: 0.0272\n",
      "Epoch [400/800], Loss: 0.0271\n",
      "Epoch [401/800], Loss: 0.0271\n",
      "Epoch [402/800], Loss: 0.0271\n",
      "Epoch [403/800], Loss: 0.0271\n",
      "Epoch [404/800], Loss: 0.0271\n",
      "Epoch [405/800], Loss: 0.0270\n",
      "Epoch [406/800], Loss: 0.0270\n",
      "Epoch [407/800], Loss: 0.0270\n",
      "Epoch [408/800], Loss: 0.0270\n",
      "Epoch [409/800], Loss: 0.0270\n",
      "Epoch [410/800], Loss: 0.0269\n",
      "Epoch [411/800], Loss: 0.0269\n",
      "Epoch [412/800], Loss: 0.0269\n",
      "Epoch [413/800], Loss: 0.0268\n",
      "Epoch [414/800], Loss: 0.0268\n",
      "Epoch [415/800], Loss: 0.0268\n",
      "Epoch [416/800], Loss: 0.0267\n",
      "Epoch [417/800], Loss: 0.0267\n",
      "Epoch [418/800], Loss: 0.0267\n",
      "Epoch [419/800], Loss: 0.0266\n",
      "Epoch [420/800], Loss: 0.0266\n",
      "Epoch [421/800], Loss: 0.0266\n",
      "Epoch [422/800], Loss: 0.0265\n",
      "Epoch [423/800], Loss: 0.0265\n",
      "Epoch [424/800], Loss: 0.0264\n",
      "Epoch [425/800], Loss: 0.0264\n",
      "Epoch [426/800], Loss: 0.0263\n",
      "Epoch [427/800], Loss: 0.0262\n",
      "Epoch [428/800], Loss: 0.0262\n",
      "Epoch [429/800], Loss: 0.0261\n",
      "Epoch [430/800], Loss: 0.0260\n",
      "Epoch [431/800], Loss: 0.0260\n",
      "Epoch [432/800], Loss: 0.0259\n",
      "Epoch [433/800], Loss: 0.0258\n",
      "Epoch [434/800], Loss: 0.0257\n",
      "Epoch [435/800], Loss: 0.0256\n",
      "Epoch [436/800], Loss: 0.0255\n",
      "Epoch [437/800], Loss: 0.0254\n",
      "Epoch [438/800], Loss: 0.0253\n",
      "Epoch [439/800], Loss: 0.0252\n",
      "Epoch [440/800], Loss: 0.0257\n",
      "Epoch [441/800], Loss: 0.0303\n",
      "Epoch [442/800], Loss: 0.0495\n",
      "Epoch [443/800], Loss: 0.0905\n",
      "Epoch [444/800], Loss: 0.0308\n",
      "Epoch [445/800], Loss: 0.0782\n",
      "Epoch [446/800], Loss: 0.0328\n",
      "Epoch [447/800], Loss: 0.0665\n",
      "Epoch [448/800], Loss: 0.0325\n",
      "Epoch [449/800], Loss: 0.0588\n",
      "Epoch [450/800], Loss: 0.0313\n",
      "Epoch [451/800], Loss: 0.0532\n",
      "Epoch [452/800], Loss: 0.0299\n",
      "Epoch [453/800], Loss: 0.0490\n",
      "Epoch [454/800], Loss: 0.0287\n",
      "Epoch [455/800], Loss: 0.0457\n",
      "Epoch [456/800], Loss: 0.0280\n",
      "Epoch [457/800], Loss: 0.0427\n",
      "Epoch [458/800], Loss: 0.0277\n",
      "Epoch [459/800], Loss: 0.0400\n",
      "Epoch [460/800], Loss: 0.0277\n",
      "Epoch [461/800], Loss: 0.0376\n",
      "Epoch [462/800], Loss: 0.0279\n",
      "Epoch [463/800], Loss: 0.0354\n",
      "Epoch [464/800], Loss: 0.0282\n",
      "Epoch [465/800], Loss: 0.0335\n",
      "Epoch [466/800], Loss: 0.0286\n",
      "Epoch [467/800], Loss: 0.0319\n",
      "Epoch [468/800], Loss: 0.0289\n",
      "Epoch [469/800], Loss: 0.0307\n",
      "Epoch [470/800], Loss: 0.0291\n",
      "Epoch [471/800], Loss: 0.0297\n",
      "Epoch [472/800], Loss: 0.0292\n",
      "Epoch [473/800], Loss: 0.0290\n",
      "Epoch [474/800], Loss: 0.0292\n",
      "Epoch [475/800], Loss: 0.0285\n",
      "Epoch [476/800], Loss: 0.0291\n",
      "Epoch [477/800], Loss: 0.0281\n",
      "Epoch [478/800], Loss: 0.0290\n",
      "Epoch [479/800], Loss: 0.0279\n",
      "Epoch [480/800], Loss: 0.0289\n",
      "Epoch [481/800], Loss: 0.0278\n",
      "Epoch [482/800], Loss: 0.0287\n",
      "Epoch [483/800], Loss: 0.0277\n",
      "Epoch [484/800], Loss: 0.0285\n",
      "Epoch [485/800], Loss: 0.0276\n",
      "Epoch [486/800], Loss: 0.0284\n",
      "Epoch [487/800], Loss: 0.0276\n",
      "Epoch [488/800], Loss: 0.0283\n",
      "Epoch [489/800], Loss: 0.0276\n",
      "Epoch [490/800], Loss: 0.0281\n",
      "Epoch [491/800], Loss: 0.0276\n",
      "Epoch [492/800], Loss: 0.0280\n",
      "Epoch [493/800], Loss: 0.0276\n",
      "Epoch [494/800], Loss: 0.0279\n",
      "Epoch [495/800], Loss: 0.0277\n",
      "Epoch [496/800], Loss: 0.0279\n",
      "Epoch [497/800], Loss: 0.0277\n",
      "Epoch [498/800], Loss: 0.0278\n",
      "Epoch [499/800], Loss: 0.0277\n",
      "Epoch [500/800], Loss: 0.0278\n",
      "Epoch [501/800], Loss: 0.0277\n",
      "Epoch [502/800], Loss: 0.0277\n",
      "Epoch [503/800], Loss: 0.0277\n",
      "Epoch [504/800], Loss: 0.0277\n",
      "Epoch [505/800], Loss: 0.0277\n",
      "Epoch [506/800], Loss: 0.0277\n",
      "Epoch [507/800], Loss: 0.0277\n",
      "Epoch [508/800], Loss: 0.0277\n",
      "Epoch [509/800], Loss: 0.0276\n",
      "Epoch [510/800], Loss: 0.0277\n",
      "Epoch [511/800], Loss: 0.0276\n",
      "Epoch [512/800], Loss: 0.0276\n",
      "Epoch [513/800], Loss: 0.0276\n",
      "Epoch [514/800], Loss: 0.0276\n",
      "Epoch [515/800], Loss: 0.0276\n",
      "Epoch [516/800], Loss: 0.0276\n",
      "Epoch [517/800], Loss: 0.0276\n",
      "Epoch [518/800], Loss: 0.0276\n",
      "Epoch [519/800], Loss: 0.0276\n",
      "Epoch [520/800], Loss: 0.0276\n",
      "Epoch [521/800], Loss: 0.0276\n",
      "Epoch [522/800], Loss: 0.0276\n",
      "Epoch [523/800], Loss: 0.0276\n",
      "Epoch [524/800], Loss: 0.0276\n",
      "Epoch [525/800], Loss: 0.0275\n",
      "Epoch [526/800], Loss: 0.0275\n",
      "Epoch [527/800], Loss: 0.0274\n",
      "Epoch [528/800], Loss: 0.0273\n",
      "Epoch [529/800], Loss: 0.0274\n",
      "Epoch [530/800], Loss: 0.0320\n",
      "Epoch [531/800], Loss: 0.0558\n",
      "Epoch [532/800], Loss: 0.0288\n",
      "Epoch [533/800], Loss: 0.0504\n",
      "Epoch [534/800], Loss: 0.0287\n",
      "Epoch [535/800], Loss: 0.0459\n",
      "Epoch [536/800], Loss: 0.0281\n",
      "Epoch [537/800], Loss: 0.0429\n",
      "Epoch [538/800], Loss: 0.0277\n",
      "Epoch [539/800], Loss: 0.0401\n",
      "Epoch [540/800], Loss: 0.0278\n",
      "Epoch [541/800], Loss: 0.0376\n",
      "Epoch [542/800], Loss: 0.0278\n",
      "Epoch [543/800], Loss: 0.0357\n",
      "Epoch [544/800], Loss: 0.0278\n",
      "Epoch [545/800], Loss: 0.0341\n",
      "Epoch [546/800], Loss: 0.0279\n",
      "Epoch [547/800], Loss: 0.0326\n",
      "Epoch [548/800], Loss: 0.0281\n",
      "Epoch [549/800], Loss: 0.0314\n",
      "Epoch [550/800], Loss: 0.0282\n",
      "Epoch [551/800], Loss: 0.0306\n",
      "Epoch [552/800], Loss: 0.0283\n",
      "Epoch [553/800], Loss: 0.0299\n",
      "Epoch [554/800], Loss: 0.0283\n",
      "Epoch [555/800], Loss: 0.0292\n",
      "Epoch [556/800], Loss: 0.0284\n",
      "Epoch [557/800], Loss: 0.0288\n",
      "Epoch [558/800], Loss: 0.0283\n",
      "Epoch [559/800], Loss: 0.0285\n",
      "Epoch [560/800], Loss: 0.0283\n",
      "Epoch [561/800], Loss: 0.0282\n",
      "Epoch [562/800], Loss: 0.0282\n",
      "Epoch [563/800], Loss: 0.0280\n",
      "Epoch [564/800], Loss: 0.0282\n",
      "Epoch [565/800], Loss: 0.0279\n",
      "Epoch [566/800], Loss: 0.0281\n",
      "Epoch [567/800], Loss: 0.0278\n",
      "Epoch [568/800], Loss: 0.0280\n",
      "Epoch [569/800], Loss: 0.0277\n",
      "Epoch [570/800], Loss: 0.0280\n",
      "Epoch [571/800], Loss: 0.0277\n",
      "Epoch [572/800], Loss: 0.0279\n",
      "Epoch [573/800], Loss: 0.0277\n",
      "Epoch [574/800], Loss: 0.0279\n",
      "Epoch [575/800], Loss: 0.0276\n",
      "Epoch [576/800], Loss: 0.0278\n",
      "Epoch [577/800], Loss: 0.0276\n",
      "Epoch [578/800], Loss: 0.0278\n",
      "Epoch [579/800], Loss: 0.0276\n",
      "Epoch [580/800], Loss: 0.0277\n",
      "Epoch [581/800], Loss: 0.0276\n",
      "Epoch [582/800], Loss: 0.0277\n",
      "Epoch [583/800], Loss: 0.0276\n",
      "Epoch [584/800], Loss: 0.0277\n",
      "Epoch [585/800], Loss: 0.0276\n",
      "Epoch [586/800], Loss: 0.0277\n",
      "Epoch [587/800], Loss: 0.0276\n",
      "Epoch [588/800], Loss: 0.0276\n",
      "Epoch [589/800], Loss: 0.0276\n",
      "Epoch [590/800], Loss: 0.0276\n",
      "Epoch [591/800], Loss: 0.0276\n",
      "Epoch [592/800], Loss: 0.0276\n",
      "Epoch [593/800], Loss: 0.0276\n",
      "Epoch [594/800], Loss: 0.0276\n",
      "Epoch [595/800], Loss: 0.0276\n",
      "Epoch [596/800], Loss: 0.0276\n",
      "Epoch [597/800], Loss: 0.0275\n",
      "Epoch [598/800], Loss: 0.0275\n",
      "Epoch [599/800], Loss: 0.0275\n",
      "Epoch [600/800], Loss: 0.0275\n",
      "Epoch [601/800], Loss: 0.0275\n",
      "Epoch [602/800], Loss: 0.0275\n",
      "Epoch [603/800], Loss: 0.0275\n",
      "Epoch [604/800], Loss: 0.0274\n",
      "Epoch [605/800], Loss: 0.0274\n",
      "Epoch [606/800], Loss: 0.0273\n",
      "Epoch [607/800], Loss: 0.0273\n",
      "Epoch [608/800], Loss: 0.0272\n",
      "Epoch [609/800], Loss: 0.0272\n",
      "Epoch [610/800], Loss: 0.0275\n",
      "Epoch [611/800], Loss: 0.0316\n",
      "Epoch [612/800], Loss: 0.0403\n",
      "Epoch [613/800], Loss: 0.0338\n",
      "Epoch [614/800], Loss: 0.0274\n",
      "Epoch [615/800], Loss: 0.0279\n",
      "Epoch [616/800], Loss: 0.0278\n",
      "Epoch [617/800], Loss: 0.0275\n",
      "Epoch [618/800], Loss: 0.0278\n",
      "Epoch [619/800], Loss: 0.0274\n",
      "Epoch [620/800], Loss: 0.0277\n",
      "Epoch [621/800], Loss: 0.0272\n",
      "Epoch [622/800], Loss: 0.0276\n",
      "Epoch [623/800], Loss: 0.0271\n",
      "Epoch [624/800], Loss: 0.0274\n",
      "Epoch [625/800], Loss: 0.0270\n",
      "Epoch [626/800], Loss: 0.0270\n",
      "Epoch [627/800], Loss: 0.0271\n",
      "Epoch [628/800], Loss: 0.0268\n",
      "Epoch [629/800], Loss: 0.0270\n",
      "Epoch [630/800], Loss: 0.0267\n",
      "Epoch [631/800], Loss: 0.0267\n",
      "Epoch [632/800], Loss: 0.0267\n",
      "Epoch [633/800], Loss: 0.0264\n",
      "Epoch [634/800], Loss: 0.0264\n",
      "Epoch [635/800], Loss: 0.0263\n",
      "Epoch [636/800], Loss: 0.0261\n",
      "Epoch [637/800], Loss: 0.0261\n",
      "Epoch [638/800], Loss: 0.0260\n",
      "Epoch [639/800], Loss: 0.0258\n",
      "Epoch [640/800], Loss: 0.0257\n",
      "Epoch [641/800], Loss: 0.0257\n",
      "Epoch [642/800], Loss: 0.0254\n",
      "Epoch [643/800], Loss: 0.0252\n",
      "Epoch [644/800], Loss: 0.0251\n",
      "Epoch [645/800], Loss: 0.0250\n",
      "Epoch [646/800], Loss: 0.0249\n",
      "Epoch [647/800], Loss: 0.0247\n",
      "Epoch [648/800], Loss: 0.0245\n",
      "Epoch [649/800], Loss: 0.0243\n",
      "Epoch [650/800], Loss: 0.0242\n",
      "Epoch [651/800], Loss: 0.0243\n",
      "Epoch [652/800], Loss: 0.0252\n",
      "Epoch [653/800], Loss: 0.0282\n",
      "Epoch [654/800], Loss: 0.0373\n",
      "Epoch [655/800], Loss: 0.0427\n",
      "Epoch [656/800], Loss: 0.0319\n",
      "Epoch [657/800], Loss: 0.0264\n",
      "Epoch [658/800], Loss: 0.0324\n",
      "Epoch [659/800], Loss: 0.0267\n",
      "Epoch [660/800], Loss: 0.0311\n",
      "Epoch [661/800], Loss: 0.0277\n",
      "Epoch [662/800], Loss: 0.0293\n",
      "Epoch [663/800], Loss: 0.0282\n",
      "Epoch [664/800], Loss: 0.0277\n",
      "Epoch [665/800], Loss: 0.0287\n",
      "Epoch [666/800], Loss: 0.0265\n",
      "Epoch [667/800], Loss: 0.0288\n",
      "Epoch [668/800], Loss: 0.0260\n",
      "Epoch [669/800], Loss: 0.0275\n",
      "Epoch [670/800], Loss: 0.0266\n",
      "Epoch [671/800], Loss: 0.0262\n",
      "Epoch [672/800], Loss: 0.0268\n",
      "Epoch [673/800], Loss: 0.0256\n",
      "Epoch [674/800], Loss: 0.0265\n",
      "Epoch [675/800], Loss: 0.0251\n",
      "Epoch [676/800], Loss: 0.0258\n",
      "Epoch [677/800], Loss: 0.0250\n",
      "Epoch [678/800], Loss: 0.0247\n",
      "Epoch [679/800], Loss: 0.0252\n",
      "Epoch [680/800], Loss: 0.0242\n",
      "Epoch [681/800], Loss: 0.0242\n",
      "Epoch [682/800], Loss: 0.0242\n",
      "Epoch [683/800], Loss: 0.0232\n",
      "Epoch [684/800], Loss: 0.0232\n",
      "Epoch [685/800], Loss: 0.0230\n",
      "Epoch [686/800], Loss: 0.0222\n",
      "Epoch [687/800], Loss: 0.0220\n",
      "Epoch [688/800], Loss: 0.0217\n",
      "Epoch [689/800], Loss: 0.0209\n",
      "Epoch [690/800], Loss: 0.0203\n",
      "Epoch [691/800], Loss: 0.0199\n",
      "Epoch [692/800], Loss: 0.0197\n",
      "Epoch [693/800], Loss: 0.0198\n",
      "Epoch [694/800], Loss: 0.0233\n",
      "Epoch [695/800], Loss: 0.0346\n",
      "Epoch [696/800], Loss: 0.0586\n",
      "Epoch [697/800], Loss: 0.0254\n",
      "Epoch [698/800], Loss: 0.0436\n",
      "Epoch [699/800], Loss: 0.0337\n",
      "Epoch [700/800], Loss: 0.0357\n",
      "Epoch [701/800], Loss: 0.0343\n",
      "Epoch [702/800], Loss: 0.0336\n",
      "Epoch [703/800], Loss: 0.0329\n",
      "Epoch [704/800], Loss: 0.0305\n",
      "Epoch [705/800], Loss: 0.0297\n",
      "Epoch [706/800], Loss: 0.0256\n",
      "Epoch [707/800], Loss: 0.0225\n",
      "Epoch [708/800], Loss: 0.0215\n",
      "Epoch [709/800], Loss: 0.0231\n",
      "Epoch [710/800], Loss: 0.0253\n",
      "Epoch [711/800], Loss: 0.0222\n",
      "Epoch [712/800], Loss: 0.0209\n",
      "Epoch [713/800], Loss: 0.0173\n",
      "Epoch [714/800], Loss: 0.0200\n",
      "Epoch [715/800], Loss: 0.0181\n",
      "Epoch [716/800], Loss: 0.0203\n",
      "Epoch [717/800], Loss: 0.0185\n",
      "Epoch [718/800], Loss: 0.0160\n",
      "Epoch [719/800], Loss: 0.0133\n",
      "Epoch [720/800], Loss: 0.0128\n",
      "Epoch [721/800], Loss: 0.0136\n",
      "Epoch [722/800], Loss: 0.0131\n",
      "Epoch [723/800], Loss: 0.0144\n",
      "Epoch [724/800], Loss: 0.0230\n",
      "Epoch [725/800], Loss: 0.0235\n",
      "Epoch [726/800], Loss: 0.0163\n",
      "Epoch [727/800], Loss: 0.0212\n",
      "Epoch [728/800], Loss: 0.0209\n",
      "Epoch [729/800], Loss: 0.0195\n",
      "Epoch [730/800], Loss: 0.0148\n",
      "Epoch [731/800], Loss: 0.0096\n",
      "Epoch [732/800], Loss: 0.0204\n",
      "Epoch [733/800], Loss: 0.0722\n",
      "Epoch [734/800], Loss: 0.0121\n",
      "Epoch [735/800], Loss: 0.0541\n",
      "Epoch [736/800], Loss: 0.0249\n",
      "Epoch [737/800], Loss: 0.0430\n",
      "Epoch [738/800], Loss: 0.0286\n",
      "Epoch [739/800], Loss: 0.0397\n",
      "Epoch [740/800], Loss: 0.0238\n",
      "Epoch [741/800], Loss: 0.0281\n",
      "Epoch [742/800], Loss: 0.0138\n",
      "Epoch [743/800], Loss: 0.0331\n",
      "Epoch [744/800], Loss: 0.0465\n",
      "Epoch [745/800], Loss: 0.0209\n",
      "Epoch [746/800], Loss: 0.0401\n",
      "Epoch [747/800], Loss: 0.0244\n",
      "Epoch [748/800], Loss: 0.0277\n",
      "Epoch [749/800], Loss: 0.0227\n",
      "Epoch [750/800], Loss: 0.0203\n",
      "Epoch [751/800], Loss: 0.0186\n",
      "Epoch [752/800], Loss: 0.0211\n",
      "Epoch [753/800], Loss: 0.0175\n",
      "Epoch [754/800], Loss: 0.0158\n",
      "Epoch [755/800], Loss: 0.0178\n",
      "Epoch [756/800], Loss: 0.0120\n",
      "Epoch [757/800], Loss: 0.0175\n",
      "Epoch [758/800], Loss: 0.0090\n",
      "Epoch [759/800], Loss: 0.0168\n",
      "Epoch [760/800], Loss: 0.0081\n",
      "Epoch [761/800], Loss: 0.0153\n",
      "Epoch [762/800], Loss: 0.0071\n",
      "Epoch [763/800], Loss: 0.0142\n",
      "Epoch [764/800], Loss: 0.0073\n",
      "Epoch [765/800], Loss: 0.0125\n",
      "Epoch [766/800], Loss: 0.0068\n",
      "Epoch [767/800], Loss: 0.0117\n",
      "Epoch [768/800], Loss: 0.0067\n",
      "Epoch [769/800], Loss: 0.0106\n",
      "Epoch [770/800], Loss: 0.0065\n",
      "Epoch [771/800], Loss: 0.0098\n",
      "Epoch [772/800], Loss: 0.0065\n",
      "Epoch [773/800], Loss: 0.0090\n",
      "Epoch [774/800], Loss: 0.0065\n",
      "Epoch [775/800], Loss: 0.0086\n",
      "Epoch [776/800], Loss: 0.0065\n",
      "Epoch [777/800], Loss: 0.0080\n",
      "Epoch [778/800], Loss: 0.0064\n",
      "Epoch [779/800], Loss: 0.0078\n",
      "Epoch [780/800], Loss: 0.0064\n",
      "Epoch [781/800], Loss: 0.0075\n",
      "Epoch [782/800], Loss: 0.0063\n",
      "Epoch [783/800], Loss: 0.0073\n",
      "Epoch [784/800], Loss: 0.0063\n",
      "Epoch [785/800], Loss: 0.0071\n",
      "Epoch [786/800], Loss: 0.0063\n",
      "Epoch [787/800], Loss: 0.0069\n",
      "Epoch [788/800], Loss: 0.0063\n",
      "Epoch [789/800], Loss: 0.0068\n",
      "Epoch [790/800], Loss: 0.0063\n",
      "Epoch [791/800], Loss: 0.0066\n",
      "Epoch [792/800], Loss: 0.0062\n",
      "Epoch [793/800], Loss: 0.0065\n",
      "Epoch [794/800], Loss: 0.0062\n",
      "Epoch [795/800], Loss: 0.0064\n",
      "Epoch [796/800], Loss: 0.0062\n",
      "Epoch [797/800], Loss: 0.0064\n",
      "Epoch [798/800], Loss: 0.0062\n",
      "Epoch [799/800], Loss: 0.0063\n",
      "Epoch [800/800], Loss: 0.0062\n",
      "After training: tensor([[44571.5352,  1277.8352],\n",
      "        [51330.7969,  1502.3345],\n",
      "        [36275.0312,  1010.9241],\n",
      "        [34182.9453,   945.2179],\n",
      "        [43239.6875,  1233.3239],\n",
      "        [46538.9805,  1341.5560],\n",
      "        [32707.6094,   900.2986],\n",
      "        [41980.5430,  1191.3094],\n",
      "        [58918.5195,  1755.1654],\n",
      "        [55268.1211,  1631.8472]], device='cuda:0')\n",
      "y: tensor([[38280.0000,  2333.0000],\n",
      "        [52575.0000,  2226.0000],\n",
      "        [28451.0000,  2161.0000],\n",
      "        [27678.0000,  2075.0000],\n",
      "        [51744.0039,  2023.0001],\n",
      "        [45578.0000,  1914.0000],\n",
      "        [37031.0000,  1750.0000],\n",
      "        [56509.0039,  1614.0000],\n",
      "        [90885.0000,  1590.0000],\n",
      "        [92148.0000,  1564.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = RNN_Model.RNN(x.shape[2], 128, 2).to(device)\n",
    "with torch.no_grad():\n",
    "    print(\"Before training:\", model(x) * ymaxtensor)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.SmoothL1Loss()\n",
    "learning_rate = 1e-2\n",
    "num_epoches = 800\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    outputs = model(x)\n",
    "\n",
    "    loss = criterion(outputs, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epoches}], Loss: {loss.item():.4f}')\n",
    "with torch.no_grad():\n",
    "    print(\"After training:\", (model(x) * ymaxtensor)[10:20])\n",
    "    print(\"y:\", (y * ymaxtensor)[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0276\n",
      "Epoch [159/800], Loss: 0.0276\n",
      "Epoch [160/800], Loss: 0.0276\n",
      "Epoch [161/800], Loss: 0.0276\n",
      "Epoch [162/800], Loss: 0.0276\n",
      "Epoch [163/800], Loss: 0.0276\n",
      "Epoch [164/800], Loss: 0.0276\n",
      "Epoch [165/800], Loss: 0.0276\n",
      "Epoch [166/800], Loss: 0.0276\n",
      "Epoch [167/800], Loss: 0.0276\n",
      "Epoch [168/800], Loss: 0.0276\n",
      "Epoch [169/800], Loss: 0.0276\n",
      "Epoch [170/800], Loss: 0.0276\n",
      "Epoch [171/800], Loss: 0.0276\n",
      "Epoch [172/800], Loss: 0.0276\n",
      "Epoch [173/800], Loss: 0.0276\n",
      "Epoch [174/800], Loss: 0.0276\n",
      "Epoch [175/800], Loss: 0.0276\n",
      "Epoch [176/800], Loss: 0.0276\n",
      "Epoch [177/800], Loss: 0.0276\n",
      "Epoch [178/800], Loss: 0.0276\n",
      "Epoch [179/800], Loss: 0.0276\n",
      "Epoch [180/800], Loss: 0.0276\n",
      "Epoch [181/800], Loss: 0.0276\n",
      "Epoch [182/800], Loss: 0.0276\n",
      "Epoch [183/800], Loss: 0.0276\n",
      "Epoch [184/800], Loss: 0.0276\n",
      "Epoch [185/800], Loss: 0.0276\n",
      "Epoch [186/800], Loss: 0.0276\n",
      "Epoch [187/800], Loss: 0.0276\n",
      "Epoch [188/800], Loss: 0.0276\n",
      "Epoch [189/800], Loss: 0.0276\n",
      "Epoch [190/800], Loss: 0.0276\n",
      "Epoch [191/800], Loss: 0.0276\n",
      "Epoch [192/800], Loss: 0.0276\n",
      "Epoch [193/800], Loss: 0.0276\n",
      "Epoch [194/800], Loss: 0.0276\n",
      "Epoch [195/800], Loss: 0.0276\n",
      "Epoch [196/800], Loss: 0.0276\n",
      "Epoch [197/800], Loss: 0.0276\n",
      "Epoch [198/800], Loss: 0.0276\n",
      "Epoch [199/800], Loss: 0.0276\n",
      "Epoch [200/800], Loss: 0.0276\n",
      "Epoch [201/800], Loss: 0.0276\n",
      "Epoch [202/800], Loss: 0.0276\n",
      "Epoch [203/800], Loss: 0.0276\n",
      "Epoch [204/800], Loss: 0.0276\n",
      "Epoch [205/800], Loss: 0.0276\n",
      "Epoch [206/800], Loss: 0.0276\n",
      "Epoch [207/800], Loss: 0.0276\n",
      "Epoch [208/800], Loss: 0.0276\n",
      "Epoch [209/800], Loss: 0.0276\n",
      "Epoch [210/800], Loss: 0.0276\n",
      "Epoch [211/800], Loss: 0.0276\n",
      "Epoch [212/800], Loss: 0.0276\n",
      "Epoch [213/800], Loss: 0.0276\n",
      "Epoch [214/800], Loss: 0.0276\n",
      "Epoch [215/800], Loss: 0.0276\n",
      "Epoch [216/800], Loss: 0.0276\n",
      "Epoch [217/800], Loss: 0.0276\n",
      "Epoch [218/800], Loss: 0.0276\n",
      "Epoch [219/800], Loss: 0.0276\n",
      "Epoch [220/800], Loss: 0.0276\n",
      "Epoch [221/800], Loss: 0.0276\n",
      "Epoch [222/800], Loss: 0.0276\n",
      "Epoch [223/800], Loss: 0.0276\n",
      "Epoch [224/800], Loss: 0.0276\n",
      "Epoch [225/800], Loss: 0.0276\n",
      "Epoch [226/800], Loss: 0.0276\n",
      "Epoch [227/800], Loss: 0.0276\n",
      "Epoch [228/800], Loss: 0.0276\n",
      "Epoch [229/800], Loss: 0.0276\n",
      "Epoch [230/800], Loss: 0.0276\n",
      "Epoch [231/800], Loss: 0.0276\n",
      "Epoch [232/800], Loss: 0.0276\n",
      "Epoch [233/800], Loss: 0.0276\n",
      "Epoch [234/800], Loss: 0.0276\n",
      "Epoch [235/800], Loss: 0.0276\n",
      "Epoch [236/800], Loss: 0.0276\n",
      "Epoch [237/800], Loss: 0.0276\n",
      "Epoch [238/800], Loss: 0.0276\n",
      "Epoch [239/800], Loss: 0.0276\n",
      "Epoch [240/800], Loss: 0.0276\n",
      "Epoch [241/800], Loss: 0.0276\n",
      "Epoch [242/800], Loss: 0.0276\n",
      "Epoch [243/800], Loss: 0.0276\n",
      "Epoch [244/800], Loss: 0.0276\n",
      "Epoch [245/800], Loss: 0.0276\n",
      "Epoch [246/800], Loss: 0.0276\n",
      "Epoch [247/800], Loss: 0.0276\n",
      "Epoch [248/800], Loss: 0.0276\n",
      "Epoch [249/800], Loss: 0.0276\n",
      "Epoch [250/800], Loss: 0.0276\n",
      "Epoch [251/800], Loss: 0.0276\n",
      "Epoch [252/800], Loss: 0.0276\n",
      "Epoch [253/800], Loss: 0.0276\n",
      "Epoch [254/800], Loss: 0.0276\n",
      "Epoch [255/800], Loss: 0.0276\n",
      "Epoch [256/800], Loss: 0.0276\n",
      "Epoch [257/800], Loss: 0.0276\n",
      "Epoch [258/800], Loss: 0.0276\n",
      "Epoch [259/800], Loss: 0.0276\n",
      "Epoch [260/800], Loss: 0.0276\n",
      "Epoch [261/800], Loss: 0.0276\n",
      "Epoch [262/800], Loss: 0.0276\n",
      "Epoch [263/800], Loss: 0.0276\n",
      "Epoch [264/800], Loss: 0.0276\n",
      "Epoch [265/800], Loss: 0.0276\n",
      "Epoch [266/800], Loss: 0.0276\n",
      "Epoch [267/800], Loss: 0.0276\n",
      "Epoch [268/800], Loss: 0.0276\n",
      "Epoch [269/800], Loss: 0.0276\n",
      "Epoch [270/800], Loss: 0.0276\n",
      "Epoch [271/800], Loss: 0.0276\n",
      "Epoch [272/800], Loss: 0.0276\n",
      "Epoch [273/800], Loss: 0.0276\n",
      "Epoch [274/800], Loss: 0.0276\n",
      "Epoch [275/800], Loss: 0.0276\n",
      "Epoch [276/800], Loss: 0.0276\n",
      "Epoch [277/800], Loss: 0.0276\n",
      "Epoch [278/800], Loss: 0.0276\n",
      "Epoch [279/800], Loss: 0.0276\n",
      "Epoch [280/800], Loss: 0.0276\n",
      "Epoch [281/800], Loss: 0.0276\n",
      "Epoch [282/800], Loss: 0.0276\n",
      "Epoch [283/800], Loss: 0.0276\n",
      "Epoch [284/800], Loss: 0.0276\n",
      "Epoch [285/800], Loss: 0.0276\n",
      "Epoch [286/800], Loss: 0.0276\n",
      "Epoch [287/800], Loss: 0.0276\n",
      "Epoch [288/800], Loss: 0.0276\n",
      "Epoch [289/800], Loss: 0.0276\n",
      "Epoch [290/800], Loss: 0.0276\n",
      "Epoch [291/800], Loss: 0.0276\n",
      "Epoch [292/800], Loss: 0.0276\n",
      "Epoch [293/800], Loss: 0.0276\n",
      "Epoch [294/800], Loss: 0.0276\n",
      "Epoch [295/800], Loss: 0.0276\n",
      "Epoch [296/800], Loss: 0.0276\n",
      "Epoch [297/800], Loss: 0.0276\n",
      "Epoch [298/800], Loss: 0.0276\n",
      "Epoch [299/800], Loss: 0.0276\n",
      "Epoch [300/800], Loss: 0.0276\n",
      "Epoch [301/800], Loss: 0.0276\n",
      "Epoch [302/800], Loss: 0.0276\n",
      "Epoch [303/800], Loss: 0.0276\n",
      "Epoch [304/800], Loss: 0.0276\n",
      "Epoch [305/800], Loss: 0.0276\n",
      "Epoch [306/800], Loss: 0.0276\n",
      "Epoch [307/800], Loss: 0.0276\n",
      "Epoch [308/800], Loss: 0.0276\n",
      "Epoch [309/800], Loss: 0.0276\n",
      "Epoch [310/800], Loss: 0.0276\n",
      "Epoch [311/800], Loss: 0.0276\n",
      "Epoch [312/800], Loss: 0.0276\n",
      "Epoch [313/800], Loss: 0.0276\n",
      "Epoch [314/800], Loss: 0.0276\n",
      "Epoch [315/800], Loss: 0.0276\n",
      "Epoch [316/800], Loss: 0.0276\n",
      "Epoch [317/800], Loss: 0.0276\n",
      "Epoch [318/800], Loss: 0.0276\n",
      "Epoch [319/800], Loss: 0.0276\n",
      "Epoch [320/800], Loss: 0.0276\n",
      "Epoch [321/800], Loss: 0.0276\n",
      "Epoch [322/800], Loss: 0.0276\n",
      "Epoch [323/800], Loss: 0.0276\n",
      "Epoch [324/800], Loss: 0.0276\n",
      "Epoch [325/800], Loss: 0.0276\n",
      "Epoch [326/800], Loss: 0.0276\n",
      "Epoch [327/800], Loss: 0.0276\n",
      "Epoch [328/800], Loss: 0.0276\n",
      "Epoch [329/800], Loss: 0.0276\n",
      "Epoch [330/800], Loss: 0.0276\n",
      "Epoch [331/800], Loss: 0.0276\n",
      "Epoch [332/800], Loss: 0.0276\n",
      "Epoch [333/800], Loss: 0.0276\n",
      "Epoch [334/800], Loss: 0.0276\n",
      "Epoch [335/800], Loss: 0.0276\n",
      "Epoch [336/800], Loss: 0.0276\n",
      "Epoch [337/800], Loss: 0.0276\n",
      "Epoch [338/800], Loss: 0.0276\n",
      "Epoch [339/800], Loss: 0.0276\n",
      "Epoch [340/800], Loss: 0.0276\n",
      "Epoch [341/800], Loss: 0.0276\n",
      "Epoch [342/800], Loss: 0.0276\n",
      "Epoch [343/800], Loss: 0.0276\n",
      "Epoch [344/800], Loss: 0.0276\n",
      "Epoch [345/800], Loss: 0.0276\n",
      "Epoch [346/800], Loss: 0.0276\n",
      "Epoch [347/800], Loss: 0.0276\n",
      "Epoch [348/800], Loss: 0.0276\n",
      "Epoch [349/800], Loss: 0.0276\n",
      "Epoch [350/800], Loss: 0.0276\n",
      "Epoch [351/800], Loss: 0.0276\n",
      "Epoch [352/800], Loss: 0.0276\n",
      "Epoch [353/800], Loss: 0.0276\n",
      "Epoch [354/800], Loss: 0.0276\n",
      "Epoch [355/800], Loss: 0.0276\n",
      "Epoch [356/800], Loss: 0.0276\n",
      "Epoch [357/800], Loss: 0.0276\n",
      "Epoch [358/800], Loss: 0.0276\n",
      "Epoch [359/800], Loss: 0.0276\n",
      "Epoch [360/800], Loss: 0.0276\n",
      "Epoch [361/800], Loss: 0.0276\n",
      "Epoch [362/800], Loss: 0.0276\n",
      "Epoch [363/800], Loss: 0.0276\n",
      "Epoch [364/800], Loss: 0.0276\n",
      "Epoch [365/800], Loss: 0.0276\n",
      "Epoch [366/800], Loss: 0.0276\n",
      "Epoch [367/800], Loss: 0.0276\n",
      "Epoch [368/800], Loss: 0.0276\n",
      "Epoch [369/800], Loss: 0.0276\n",
      "Epoch [370/800], Loss: 0.0276\n",
      "Epoch [371/800], Loss: 0.0276\n",
      "Epoch [372/800], Loss: 0.0276\n",
      "Epoch [373/800], Loss: 0.0276\n",
      "Epoch [374/800], Loss: 0.0276\n",
      "Epoch [375/800], Loss: 0.0276\n",
      "Epoch [376/800], Loss: 0.0276\n",
      "Epoch [377/800], Loss: 0.0276\n",
      "Epoch [378/800], Loss: 0.0276\n",
      "Epoch [379/800], Loss: 0.0276\n",
      "Epoch [380/800], Loss: 0.0276\n",
      "Epoch [381/800], Loss: 0.0276\n",
      "Epoch [382/800], Loss: 0.0276\n",
      "Epoch [383/800], Loss: 0.0276\n",
      "Epoch [384/800], Loss: 0.0276\n",
      "Epoch [385/800], Loss: 0.0276\n",
      "Epoch [386/800], Loss: 0.0276\n",
      "Epoch [387/800], Loss: 0.0276\n",
      "Epoch [388/800], Loss: 0.0276\n",
      "Epoch [389/800], Loss: 0.0276\n",
      "Epoch [390/800], Loss: 0.0276\n",
      "Epoch [391/800], Loss: 0.0276\n",
      "Epoch [392/800], Loss: 0.0276\n",
      "Epoch [393/800], Loss: 0.0276\n",
      "Epoch [394/800], Loss: 0.0276\n",
      "Epoch [395/800], Loss: 0.0276\n",
      "Epoch [396/800], Loss: 0.0276\n",
      "Epoch [397/800], Loss: 0.0276\n",
      "Epoch [398/800], Loss: 0.0276\n",
      "Epoch [399/800], Loss: 0.0276\n",
      "Epoch [400/800], Loss: 0.0276\n",
      "Epoch [401/800], Loss: 0.0276\n",
      "Epoch [402/800], Loss: 0.0276\n",
      "Epoch [403/800], Loss: 0.0276\n",
      "Epoch [404/800], Loss: 0.0276\n",
      "Epoch [405/800], Loss: 0.0276\n",
      "Epoch [406/800], Loss: 0.0276\n",
      "Epoch [407/800], Loss: 0.0276\n",
      "Epoch [408/800], Loss: 0.0276\n",
      "Epoch [409/800], Loss: 0.0276\n",
      "Epoch [410/800], Loss: 0.0276\n",
      "Epoch [411/800], Loss: 0.0276\n",
      "Epoch [412/800], Loss: 0.0276\n",
      "Epoch [413/800], Loss: 0.0276\n",
      "Epoch [414/800], Loss: 0.0276\n",
      "Epoch [415/800], Loss: 0.0276\n",
      "Epoch [416/800], Loss: 0.0276\n",
      "Epoch [417/800], Loss: 0.0276\n",
      "Epoch [418/800], Loss: 0.0276\n",
      "Epoch [419/800], Loss: 0.0276\n",
      "Epoch [420/800], Loss: 0.0276\n",
      "Epoch [421/800], Loss: 0.0276\n",
      "Epoch [422/800], Loss: 0.0276\n",
      "Epoch [423/800], Loss: 0.0276\n",
      "Epoch [424/800], Loss: 0.0276\n",
      "Epoch [425/800], Loss: 0.0276\n",
      "Epoch [426/800], Loss: 0.0276\n",
      "Epoch [427/800], Loss: 0.0276\n",
      "Epoch [428/800], Loss: 0.0276\n",
      "Epoch [429/800], Loss: 0.0276\n",
      "Epoch [430/800], Loss: 0.0276\n",
      "Epoch [431/800], Loss: 0.0276\n",
      "Epoch [432/800], Loss: 0.0276\n",
      "Epoch [433/800], Loss: 0.0276\n",
      "Epoch [434/800], Loss: 0.0276\n",
      "Epoch [435/800], Loss: 0.0276\n",
      "Epoch [436/800], Loss: 0.0276\n",
      "Epoch [437/800], Loss: 0.0277\n",
      "Epoch [438/800], Loss: 0.0290\n",
      "Epoch [439/800], Loss: 0.0276\n",
      "Epoch [440/800], Loss: 0.0279\n",
      "Epoch [441/800], Loss: 0.0280\n",
      "Epoch [442/800], Loss: 0.0278\n",
      "Epoch [443/800], Loss: 0.0277\n",
      "Epoch [444/800], Loss: 0.0280\n",
      "Epoch [445/800], Loss: 0.0278\n",
      "Epoch [446/800], Loss: 0.0277\n",
      "Epoch [447/800], Loss: 0.0279\n",
      "Epoch [448/800], Loss: 0.0278\n",
      "Epoch [449/800], Loss: 0.0277\n",
      "Epoch [450/800], Loss: 0.0278\n",
      "Epoch [451/800], Loss: 0.0278\n",
      "Epoch [452/800], Loss: 0.0276\n",
      "Epoch [453/800], Loss: 0.0278\n",
      "Epoch [454/800], Loss: 0.0277\n",
      "Epoch [455/800], Loss: 0.0276\n",
      "Epoch [456/800], Loss: 0.0277\n",
      "Epoch [457/800], Loss: 0.0277\n",
      "Epoch [458/800], Loss: 0.0276\n",
      "Epoch [459/800], Loss: 0.0277\n",
      "Epoch [460/800], Loss: 0.0277\n",
      "Epoch [461/800], Loss: 0.0276\n",
      "Epoch [462/800], Loss: 0.0277\n",
      "Epoch [463/800], Loss: 0.0277\n",
      "Epoch [464/800], Loss: 0.0276\n",
      "Epoch [465/800], Loss: 0.0277\n",
      "Epoch [466/800], Loss: 0.0277\n",
      "Epoch [467/800], Loss: 0.0276\n",
      "Epoch [468/800], Loss: 0.0277\n",
      "Epoch [469/800], Loss: 0.0277\n",
      "Epoch [470/800], Loss: 0.0276\n",
      "Epoch [471/800], Loss: 0.0277\n",
      "Epoch [472/800], Loss: 0.0277\n",
      "Epoch [473/800], Loss: 0.0276\n",
      "Epoch [474/800], Loss: 0.0276\n",
      "Epoch [475/800], Loss: 0.0277\n",
      "Epoch [476/800], Loss: 0.0276\n",
      "Epoch [477/800], Loss: 0.0276\n",
      "Epoch [478/800], Loss: 0.0277\n",
      "Epoch [479/800], Loss: 0.0276\n",
      "Epoch [480/800], Loss: 0.0276\n",
      "Epoch [481/800], Loss: 0.0276\n",
      "Epoch [482/800], Loss: 0.0276\n",
      "Epoch [483/800], Loss: 0.0276\n",
      "Epoch [484/800], Loss: 0.0276\n",
      "Epoch [485/800], Loss: 0.0276\n",
      "Epoch [486/800], Loss: 0.0276\n",
      "Epoch [487/800], Loss: 0.0276\n",
      "Epoch [488/800], Loss: 0.0276\n",
      "Epoch [489/800], Loss: 0.0276\n",
      "Epoch [490/800], Loss: 0.0276\n",
      "Epoch [491/800], Loss: 0.0276\n",
      "Epoch [492/800], Loss: 0.0276\n",
      "Epoch [493/800], Loss: 0.0276\n",
      "Epoch [494/800], Loss: 0.0276\n",
      "Epoch [495/800], Loss: 0.0276\n",
      "Epoch [496/800], Loss: 0.0276\n",
      "Epoch [497/800], Loss: 0.0276\n",
      "Epoch [498/800], Loss: 0.0276\n",
      "Epoch [499/800], Loss: 0.0276\n",
      "Epoch [500/800], Loss: 0.0276\n",
      "Epoch [501/800], Loss: 0.0276\n",
      "Epoch [502/800], Loss: 0.0276\n",
      "Epoch [503/800], Loss: 0.0276\n",
      "Epoch [504/800], Loss: 0.0276\n",
      "Epoch [505/800], Loss: 0.0276\n",
      "Epoch [506/800], Loss: 0.0276\n",
      "Epoch [507/800], Loss: 0.0276\n",
      "Epoch [508/800], Loss: 0.0276\n",
      "Epoch [509/800], Loss: 0.0276\n",
      "Epoch [510/800], Loss: 0.0276\n",
      "Epoch [511/800], Loss: 0.0276\n",
      "Epoch [512/800], Loss: 0.0276\n",
      "Epoch [513/800], Loss: 0.0276\n",
      "Epoch [514/800], Loss: 0.0276\n",
      "Epoch [515/800], Loss: 0.0276\n",
      "Epoch [516/800], Loss: 0.0276\n",
      "Epoch [517/800], Loss: 0.0276\n",
      "Epoch [518/800], Loss: 0.0276\n",
      "Epoch [519/800], Loss: 0.0276\n",
      "Epoch [520/800], Loss: 0.0276\n",
      "Epoch [521/800], Loss: 0.0276\n",
      "Epoch [522/800], Loss: 0.0276\n",
      "Epoch [523/800], Loss: 0.0276\n",
      "Epoch [524/800], Loss: 0.0276\n",
      "Epoch [525/800], Loss: 0.0276\n",
      "Epoch [526/800], Loss: 0.0276\n",
      "Epoch [527/800], Loss: 0.0276\n",
      "Epoch [528/800], Loss: 0.0276\n",
      "Epoch [529/800], Loss: 0.0276\n",
      "Epoch [530/800], Loss: 0.0276\n",
      "Epoch [531/800], Loss: 0.0276\n",
      "Epoch [532/800], Loss: 0.0276\n",
      "Epoch [533/800], Loss: 0.0276\n",
      "Epoch [534/800], Loss: 0.0276\n",
      "Epoch [535/800], Loss: 0.0276\n",
      "Epoch [536/800], Loss: 0.0276\n",
      "Epoch [537/800], Loss: 0.0276\n",
      "Epoch [538/800], Loss: 0.0276\n",
      "Epoch [539/800], Loss: 0.0276\n",
      "Epoch [540/800], Loss: 0.0276\n",
      "Epoch [541/800], Loss: 0.0276\n",
      "Epoch [542/800], Loss: 0.0276\n",
      "Epoch [543/800], Loss: 0.0276\n",
      "Epoch [544/800], Loss: 0.0276\n",
      "Epoch [545/800], Loss: 0.0276\n",
      "Epoch [546/800], Loss: 0.0276\n",
      "Epoch [547/800], Loss: 0.0276\n",
      "Epoch [548/800], Loss: 0.0276\n",
      "Epoch [549/800], Loss: 0.0276\n",
      "Epoch [550/800], Loss: 0.0276\n",
      "Epoch [551/800], Loss: 0.0276\n",
      "Epoch [552/800], Loss: 0.0276\n",
      "Epoch [553/800], Loss: 0.0276\n",
      "Epoch [554/800], Loss: 0.0276\n",
      "Epoch [555/800], Loss: 0.0276\n",
      "Epoch [556/800], Loss: 0.0276\n",
      "Epoch [557/800], Loss: 0.0276\n",
      "Epoch [558/800], Loss: 0.0276\n",
      "Epoch [559/800], Loss: 0.0276\n",
      "Epoch [560/800], Loss: 0.0276\n",
      "Epoch [561/800], Loss: 0.0276\n",
      "Epoch [562/800], Loss: 0.0276\n",
      "Epoch [563/800], Loss: 0.0276\n",
      "Epoch [564/800], Loss: 0.0276\n",
      "Epoch [565/800], Loss: 0.0276\n",
      "Epoch [566/800], Loss: 0.0276\n",
      "Epoch [567/800], Loss: 0.0276\n",
      "Epoch [568/800], Loss: 0.0276\n",
      "Epoch [569/800], Loss: 0.0276\n",
      "Epoch [570/800], Loss: 0.0276\n",
      "Epoch [571/800], Loss: 0.0276\n",
      "Epoch [572/800], Loss: 0.0276\n",
      "Epoch [573/800], Loss: 0.0276\n",
      "Epoch [574/800], Loss: 0.0276\n",
      "Epoch [575/800], Loss: 0.0276\n",
      "Epoch [576/800], Loss: 0.0276\n",
      "Epoch [577/800], Loss: 0.0276\n",
      "Epoch [578/800], Loss: 0.0276\n",
      "Epoch [579/800], Loss: 0.0276\n",
      "Epoch [580/800], Loss: 0.0276\n",
      "Epoch [581/800], Loss: 0.0276\n",
      "Epoch [582/800], Loss: 0.0276\n",
      "Epoch [583/800], Loss: 0.0276\n",
      "Epoch [584/800], Loss: 0.0276\n",
      "Epoch [585/800], Loss: 0.0276\n",
      "Epoch [586/800], Loss: 0.0276\n",
      "Epoch [587/800], Loss: 0.0276\n",
      "Epoch [588/800], Loss: 0.0276\n",
      "Epoch [589/800], Loss: 0.0276\n",
      "Epoch [590/800], Loss: 0.0276\n",
      "Epoch [591/800], Loss: 0.0276\n",
      "Epoch [592/800], Loss: 0.0276\n",
      "Epoch [593/800], Loss: 0.0276\n",
      "Epoch [594/800], Loss: 0.0276\n",
      "Epoch [595/800], Loss: 0.0276\n",
      "Epoch [596/800], Loss: 0.0276\n",
      "Epoch [597/800], Loss: 0.0276\n",
      "Epoch [598/800], Loss: 0.0276\n",
      "Epoch [599/800], Loss: 0.0276\n",
      "Epoch [600/800], Loss: 0.0276\n",
      "Epoch [601/800], Loss: 0.0276\n",
      "Epoch [602/800], Loss: 0.0276\n",
      "Epoch [603/800], Loss: 0.0276\n",
      "Epoch [604/800], Loss: 0.0276\n",
      "Epoch [605/800], Loss: 0.0276\n",
      "Epoch [606/800], Loss: 0.0276\n",
      "Epoch [607/800], Loss: 0.0276\n",
      "Epoch [608/800], Loss: 0.0276\n",
      "Epoch [609/800], Loss: 0.0276\n",
      "Epoch [610/800], Loss: 0.0276\n",
      "Epoch [611/800], Loss: 0.0276\n",
      "Epoch [612/800], Loss: 0.0276\n",
      "Epoch [613/800], Loss: 0.0276\n",
      "Epoch [614/800], Loss: 0.0276\n",
      "Epoch [615/800], Loss: 0.0276\n",
      "Epoch [616/800], Loss: 0.0276\n",
      "Epoch [617/800], Loss: 0.0276\n",
      "Epoch [618/800], Loss: 0.0276\n",
      "Epoch [619/800], Loss: 0.0276\n",
      "Epoch [620/800], Loss: 0.0276\n",
      "Epoch [621/800], Loss: 0.0276\n",
      "Epoch [622/800], Loss: 0.0276\n",
      "Epoch [623/800], Loss: 0.0276\n",
      "Epoch [624/800], Loss: 0.0276\n",
      "Epoch [625/800], Loss: 0.0276\n",
      "Epoch [626/800], Loss: 0.0276\n",
      "Epoch [627/800], Loss: 0.0276\n",
      "Epoch [628/800], Loss: 0.0276\n",
      "Epoch [629/800], Loss: 0.0276\n",
      "Epoch [630/800], Loss: 0.0276\n",
      "Epoch [631/800], Loss: 0.0276\n",
      "Epoch [632/800], Loss: 0.0276\n",
      "Epoch [633/800], Loss: 0.0276\n",
      "Epoch [634/800], Loss: 0.0276\n",
      "Epoch [635/800], Loss: 0.0276\n",
      "Epoch [636/800], Loss: 0.0276\n",
      "Epoch [637/800], Loss: 0.0276\n",
      "Epoch [638/800], Loss: 0.0276\n",
      "Epoch [639/800], Loss: 0.0276\n",
      "Epoch [640/800], Loss: 0.0276\n",
      "Epoch [641/800], Loss: 0.0276\n",
      "Epoch [642/800], Loss: 0.0276\n",
      "Epoch [643/800], Loss: 0.0276\n",
      "Epoch [644/800], Loss: 0.0276\n",
      "Epoch [645/800], Loss: 0.0276\n",
      "Epoch [646/800], Loss: 0.0276\n",
      "Epoch [647/800], Loss: 0.0276\n",
      "Epoch [648/800], Loss: 0.0276\n",
      "Epoch [649/800], Loss: 0.0276\n",
      "Epoch [650/800], Loss: 0.0276\n",
      "Epoch [651/800], Loss: 0.0276\n",
      "Epoch [652/800], Loss: 0.0276\n",
      "Epoch [653/800], Loss: 0.0276\n",
      "Epoch [654/800], Loss: 0.0276\n",
      "Epoch [655/800], Loss: 0.0276\n",
      "Epoch [656/800], Loss: 0.0276\n",
      "Epoch [657/800], Loss: 0.0276\n",
      "Epoch [658/800], Loss: 0.0276\n",
      "Epoch [659/800], Loss: 0.0276\n",
      "Epoch [660/800], Loss: 0.0276\n",
      "Epoch [661/800], Loss: 0.0276\n",
      "Epoch [662/800], Loss: 0.0276\n",
      "Epoch [663/800], Loss: 0.0276\n",
      "Epoch [664/800], Loss: 0.0276\n",
      "Epoch [665/800], Loss: 0.0276\n",
      "Epoch [666/800], Loss: 0.0276\n",
      "Epoch [667/800], Loss: 0.0276\n",
      "Epoch [668/800], Loss: 0.0276\n",
      "Epoch [669/800], Loss: 0.0276\n",
      "Epoch [670/800], Loss: 0.0276\n",
      "Epoch [671/800], Loss: 0.0276\n",
      "Epoch [672/800], Loss: 0.0276\n",
      "Epoch [673/800], Loss: 0.0276\n",
      "Epoch [674/800], Loss: 0.0276\n",
      "Epoch [675/800], Loss: 0.0276\n",
      "Epoch [676/800], Loss: 0.0276\n",
      "Epoch [677/800], Loss: 0.0276\n",
      "Epoch [678/800], Loss: 0.0276\n",
      "Epoch [679/800], Loss: 0.0276\n",
      "Epoch [680/800], Loss: 0.0276\n",
      "Epoch [681/800], Loss: 0.0276\n",
      "Epoch [682/800], Loss: 0.0276\n",
      "Epoch [683/800], Loss: 0.0276\n",
      "Epoch [684/800], Loss: 0.0276\n",
      "Epoch [685/800], Loss: 0.0276\n",
      "Epoch [686/800], Loss: 0.0276\n",
      "Epoch [687/800], Loss: 0.0276\n",
      "Epoch [688/800], Loss: 0.0276\n",
      "Epoch [689/800], Loss: 0.0276\n",
      "Epoch [690/800], Loss: 0.0276\n",
      "Epoch [691/800], Loss: 0.0276\n",
      "Epoch [692/800], Loss: 0.0276\n",
      "Epoch [693/800], Loss: 0.0276\n",
      "Epoch [694/800], Loss: 0.0276\n",
      "Epoch [695/800], Loss: 0.0276\n",
      "Epoch [696/800], Loss: 0.0276\n",
      "Epoch [697/800], Loss: 0.0276\n",
      "Epoch [698/800], Loss: 0.0276\n",
      "Epoch [699/800], Loss: 0.0276\n",
      "Epoch [700/800], Loss: 0.0276\n",
      "Epoch [701/800], Loss: 0.0276\n",
      "Epoch [702/800], Loss: 0.0276\n",
      "Epoch [703/800], Loss: 0.0276\n",
      "Epoch [704/800], Loss: 0.0276\n",
      "Epoch [705/800], Loss: 0.0276\n",
      "Epoch [706/800], Loss: 0.0276\n",
      "Epoch [707/800], Loss: 0.0276\n",
      "Epoch [708/800], Loss: 0.0276\n",
      "Epoch [709/800], Loss: 0.0276\n",
      "Epoch [710/800], Loss: 0.0276\n",
      "Epoch [711/800], Loss: 0.0276\n",
      "Epoch [712/800], Loss: 0.0276\n",
      "Epoch [713/800], Loss: 0.0276\n",
      "Epoch [714/800], Loss: 0.0276\n",
      "Epoch [715/800], Loss: 0.0276\n",
      "Epoch [716/800], Loss: 0.0276\n",
      "Epoch [717/800], Loss: 0.0276\n",
      "Epoch [718/800], Loss: 0.0276\n",
      "Epoch [719/800], Loss: 0.0276\n",
      "Epoch [720/800], Loss: 0.0276\n",
      "Epoch [721/800], Loss: 0.0276\n",
      "Epoch [722/800], Loss: 0.0276\n",
      "Epoch [723/800], Loss: 0.0276\n",
      "Epoch [724/800], Loss: 0.0276\n",
      "Epoch [725/800], Loss: 0.0276\n",
      "Epoch [726/800], Loss: 0.0276\n",
      "Epoch [727/800], Loss: 0.0276\n",
      "Epoch [728/800], Loss: 0.0276\n",
      "Epoch [729/800], Loss: 0.0276\n",
      "Epoch [730/800], Loss: 0.0276\n",
      "Epoch [731/800], Loss: 0.0276\n",
      "Epoch [732/800], Loss: 0.0276\n",
      "Epoch [733/800], Loss: 0.0276\n",
      "Epoch [734/800], Loss: 0.0276\n",
      "Epoch [735/800], Loss: 0.0276\n",
      "Epoch [736/800], Loss: 0.0276\n",
      "Epoch [737/800], Loss: 0.0276\n",
      "Epoch [738/800], Loss: 0.0276\n",
      "Epoch [739/800], Loss: 0.0276\n",
      "Epoch [740/800], Loss: 0.0276\n",
      "Epoch [741/800], Loss: 0.0276\n",
      "Epoch [742/800], Loss: 0.0276\n",
      "Epoch [743/800], Loss: 0.0276\n",
      "Epoch [744/800], Loss: 0.0276\n",
      "Epoch [745/800], Loss: 0.0276\n",
      "Epoch [746/800], Loss: 0.0276\n",
      "Epoch [747/800], Loss: 0.0276\n",
      "Epoch [748/800], Loss: 0.0276\n",
      "Epoch [749/800], Loss: 0.0276\n",
      "Epoch [750/800], Loss: 0.0276\n",
      "Epoch [751/800], Loss: 0.0276\n",
      "Epoch [752/800], Loss: 0.0276\n",
      "Epoch [753/800], Loss: 0.0276\n",
      "Epoch [754/800], Loss: 0.0276\n",
      "Epoch [755/800], Loss: 0.0276\n",
      "Epoch [756/800], Loss: 0.0276\n",
      "Epoch [757/800], Loss: 0.0276\n",
      "Epoch [758/800], Loss: 0.0276\n",
      "Epoch [759/800], Loss: 0.0276\n",
      "Epoch [760/800], Loss: 0.0276\n",
      "Epoch [761/800], Loss: 0.0276\n",
      "Epoch [762/800], Loss: 0.0276\n",
      "Epoch [763/800], Loss: 0.0276\n",
      "Epoch [764/800], Loss: 0.0276\n",
      "Epoch [765/800], Loss: 0.0276\n",
      "Epoch [766/800], Loss: 0.0276\n",
      "Epoch [767/800], Loss: 0.0276\n",
      "Epoch [768/800], Loss: 0.0276\n",
      "Epoch [769/800], Loss: 0.0276\n",
      "Epoch [770/800], Loss: 0.0276\n",
      "Epoch [771/800], Loss: 0.0276\n",
      "Epoch [772/800], Loss: 0.0276\n",
      "Epoch [773/800], Loss: 0.0276\n",
      "Epoch [774/800], Loss: 0.0276\n",
      "Epoch [775/800], Loss: 0.0276\n",
      "Epoch [776/800], Loss: 0.0276\n",
      "Epoch [777/800], Loss: 0.0276\n",
      "Epoch [778/800], Loss: 0.0276\n",
      "Epoch [779/800], Loss: 0.0276\n",
      "Epoch [780/800], Loss: 0.0276\n",
      "Epoch [781/800], Loss: 0.0276\n",
      "Epoch [782/800], Loss: 0.0276\n",
      "Epoch [783/800], Loss: 0.0276\n",
      "Epoch [784/800], Loss: 0.0276\n",
      "Epoch [785/800], Loss: 0.0276\n",
      "Epoch [786/800], Loss: 0.0276\n",
      "Epoch [787/800], Loss: 0.0276\n",
      "Epoch [788/800], Loss: 0.0276\n",
      "Epoch [789/800], Loss: 0.0276\n",
      "Epoch [790/800], Loss: 0.0276\n",
      "Epoch [791/800], Loss: 0.0276\n",
      "Epoch [792/800], Loss: 0.0276\n",
      "Epoch [793/800], Loss: 0.0276\n",
      "Epoch [794/800], Loss: 0.0276\n",
      "Epoch [795/800], Loss: 0.0276\n",
      "Epoch [796/800], Loss: 0.0276\n",
      "Epoch [797/800], Loss: 0.0276\n",
      "Epoch [798/800], Loss: 0.0276\n",
      "Epoch [799/800], Loss: 0.0276\n",
      "Epoch [800/800], Loss: 0.0276\n",
      "After training: tensor([[43132.8828,  1354.5499],\n",
      "        [43132.8828,  1354.5499],\n",
      "        [43132.8828,  1354.5499],\n",
      "        [43132.8828,  1354.5499],\n",
      "        [43132.8828,  1354.5499],\n",
      "        [43132.8828,  1354.5499],\n",
      "        [43132.8828,  1354.5499],\n",
      "        [43132.8828,  1354.5499],\n",
      "        [43132.8828,  1354.5499],\n",
      "        [43132.8828,  1354.5499]], device='cuda:0')\n",
      "y: tensor([[38280.0000,  2333.0000],\n",
      "        [52575.0000,  2226.0000],\n",
      "        [28451.0000,  2161.0000],\n",
      "        [27678.0000,  2075.0000],\n",
      "        [51744.0039,  2023.0001],\n",
      "        [45578.0000,  1914.0000],\n",
      "        [37031.0000,  1750.0000],\n",
      "        [56509.0039,  1614.0000],\n",
      "        [90885.0000,  1590.0000],\n",
      "        [92148.0000,  1564.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = RNN_Model.RNN(x.shape[2], 128, 2).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"Before training:\", model(x) * ymaxtensor)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.SmoothL1Loss()\n",
    "learning_rate = 1e-2\n",
    "num_epoches = 800\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    outputs = model(x)\n",
    "\n",
    "    loss = criterion(outputs, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epoches}], Loss: {loss.item():.4f}')\n",
    "with torch.no_grad():\n",
    "    print(\"After training:\", (model(x) * ymaxtensor)[10:20])\n",
    "    print(\"y:\", (y * ymaxtensor)[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 1. Batch Gradient Descent\n",
    "# 2. Handle NaN case\n",
    "# 3. clean up code"
   ]
  }
 ]
}